{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"/root <code> in o11y </code>","text":""},{"location":"1-0-1/","title":"Contributors","text":"<p> <code>@bg @ps</code> </p>"},{"location":"1-0.agenda/","title":"Agenda","text":"<ol> <li>Evolution   \ud83d\udc20 \ud83d\udc0a  \ud83d\udc12 \ud83d\udeb6\u200d\u2642\ufe0f</li> <li>Opetelemetry supported runtimes &amp; its adaptability.</li> <li>Metrics, Logs, Traces, Golden Signals.</li> <li>Practical use-case in modern deployments  \ud83c\udfa5 <code>Live Demo</code> k8s</li> <li>Tuning OTEL components.</li> <li>Roadmap &amp; Future - Brief about auto instrumentation, eBPF based &amp; non-eBPF<ul> <li>Minimal to zero code changes, e2e insights, full visibility, etc.,</li> </ul> </li> </ol>"},{"location":"1-0.agenda/#_1","title":"\ud83d\udd2d","text":""},{"location":"1-1.brief/","title":"Evolution &amp; Feasibility","text":""},{"location":"1-1.brief/#history-of-monitoring-in-tech-space","title":"History of Monitoring in Tech Space","text":"<ul> <li>Monitoring in the tech space has a long history, dating back to the early days of computing. </li> <li>As systems grew in complexity, the need for monitoring and observability increased. </li> <li>Initially, monitoring was a manual process that required human intervention. </li> <li>However, with the development of scripting and automation, monitoring became more efficient and scalable. </li> <li>The evolution of monitoring is illustrated in the timeline below.</li> </ul>"},{"location":"1-1.brief/#monitoring-over-the-years","title":"Monitoring Over the Years","text":"<pre><code>gantt\n    title Monitoring Evolution\n    dateFormat  YYYY-MM-DD\n    section Manual Monitoring\n    A : 1970-01-01, 1980-12-31\n    section Scripted Monitoring\n    B : 1981-01-01, 1990-12-31\n    section Centralized Monitoring\n    C : 1991-01-01, 2000-12-31\n    section Distributed Monitoring\n    D : 2001-01-01, 2010-12-31\n    section Microservices Monitoring\n    E : 2011-01-01, 2020-12-31\n    section Cloud-Native Monitoring\n    F : 2021-01-01, 2030-12-31\n    section Continuous Profiling\n    G : 2021-01-01, 2030-12-31\n    section AI-Driven Monitoring\n    H : 2031-01-01, 2040-12-31\n</code></pre>"},{"location":"1-1.brief/#otel-brief","title":"OTEL Brief","text":"<p>Open Standard for all MiSvc Telemetry.</p> <ul> <li>OpenTelemetry is needed for comprehensive observability in modern distributed systems. </li> <li>It provides a standardized approach to capturing distributed traces and metrics, enabling developers to gain insights into the performance and behavior of their applications across various microservices and cloud-native environments. </li> <li>With OpenTelemetry, organizations can achieve end-to-end visibility, troubleshoot issues, and optimize the performance of their applications, ultimately enhancing the overall user experience.</li> <li>OpenTelemetry is an open standard for observability data, providing a single set of APIs, libraries, agents, and instrumentation for capturing distributed traces and metrics.</li> <li>It enables developers to instrument their applications in a vendor-agnostic manner, allowing them to send telemetry data to the monitoring platform of their choice.</li> <li>OpenTelemetry aims to unify the collection of distributed traces and metrics for all applications, regardless of their programming language or framework.</li> </ul>"},{"location":"1-1.brief/#unique-aspects-of-opentelemetry-over-apms","title":"Unique Aspects of OpenTelemetry over APMs","text":"<ol> <li> <p>Vendor-Agnostic Approach: OpenTelemetry provides a vendor-agnostic approach to observability, allowing users to send telemetry data to various monitoring platforms without being tied to a specific vendor.</p> </li> <li> <p>Standardization: OpenTelemetry is an open standard for observability data, ensuring consistency and interoperability across different systems and tools.</p> </li> <li> <p>Community-Driven: OpenTelemetry is a community-driven project with contributions from various organizations and individuals, ensuring continuous improvement and innovation.</p> </li> <li> <p>Instrumentation Flexibility: OpenTelemetry offers flexibility in instrumentation, supporting multiple programming languages and frameworks, making it easier to integrate with diverse applications.</p> </li> <li> <p>Extensibility: OpenTelemetry is highly extensible, allowing users to customize and extend its capabilities based on their specific monitoring requirements.</p> </li> </ol>"},{"location":"1-1.brief/#opentelemetry-sdk-language-support","title":"OpenTelemetry SDK Language Support","text":"<pre><code>  Languages\n  \u251c\u2500\u2500 JVM Languages\n  \u2502   \u2514\u2500\u2500 Java\n  \u251c\u2500\u2500 Scripting Languages\n  \u2502   \u251c\u2500\u2500 Python\n  \u2502   \u251c\u2500\u2500 JavaScript\n  \u2502   \u251c\u2500\u2500 Ruby\n  \u2502   \u2514\u2500\u2500 PHP\n  \u251c\u2500\u2500 Compiled Languages\n  \u2502   \u251c\u2500\u2500 Go\n  \u2502   \u251c\u2500\u2500 .NET\n  \u2502   \u251c\u2500\u2500 C++\n  \u2502   \u2514\u2500\u2500 Rust\n  \u2514\u2500\u2500 Other Languages\n      \u251c\u2500\u2500 Erlang\n      \u251c\u2500\u2500 Swift\n      \u2514\u2500\u2500 Objective-C\n</code></pre>"},{"location":"2.mltp/","title":"MLTP","text":""},{"location":"2.mltp/#metrics","title":"Metrics","text":"<ul> <li>What is it?</li> <li>Read World Similarity</li> <li>Sample     <pre><code>metric_name{label=\"value\", ..} measurement\n...\nhistogram_name{label=\"value\", ..} bucket\n</code></pre></li> </ul>"},{"location":"2.mltp/#logs","title":"Logs","text":"<ul> <li>Who doesn't know it?</li> <li>Collect it to centralised storage, so we can link to our Central Monitoring-UI like <code>Grafana</code></li> <li>Sample Data Model     <pre><code>log_id: \"unique identifier for the log\"\ntimestamp: \"timestamp when the log was generated\"\nmessage: \"content of the log\"\nseverity: \"level of severity of the log\"\ntags: \"key-value pairs for additional information\"\n</code></pre></li> </ul>"},{"location":"2.mltp/#traces","title":"Traces","text":"<ul> <li>Tracing is a method used to monitor and understand the flow of a request through a distributed system.</li> <li>Read World Example of a Trace</li> <li>Microservice Example of a Trace - <code>@graph.wealthy</code></li> <li>Sample Data Model     <pre><code>trace_id: \"unique identifier for the trace\"\nspan_id: \"unique identifier for the span\"\nparent_span_id: \"id of the parent span\"\nstart_time: \"timestamp when the span started\"\nend_time: \"timestamp when the span ended\"\noperation_name: \"name of the operation\"\ntags: \"key-value pairs for additional information\"\nlogs: \"events that occurred during the span\"\n</code></pre></li> </ul>"},{"location":"2.mltp/#continuous-profiling","title":"Continuous Profiling","text":"<ul> <li>Continuous Profiling is like a doctor checking your health regularly, not just when you're sick.</li> <li>It helps us understand how our system is performing over time, not just when there's a problem.</li> <li>Sample Data Model     <pre><code>profile_id: \"unique identifier for the profile\"\nstart_time: \"timestamp when the profiling started\"\nend_time: \"timestamp when the profiling ended\"\nduration: \"duration of the profiling\"\ncpu_time: \"total CPU time used during the profiling\"\nmemory_usage: \"total memory used during the profiling\"\ndisk_io: \"total disk I/O during the profiling\"\nnetwork_io: \"total network I/O during the profiling\"\n</code></pre></li> </ul>"},{"location":"2.mltp/#flamegraph","title":"Flamegraph  \ud83d\udd25","text":"<ul> <li>Flamegraph is a visualization tool that presents a graphical representation of the execution of a program.</li> <li>It helps us understand the flow of execution and identify performance bottlenecks.</li> <li>Google Chrome as example &amp; Demo flame</li> </ul>"},{"location":"2.mltp/#golden-signals","title":"Golden Signals \ud83d\udea6","text":""},{"location":"2.mltp/#from-sre-handbook","title":"From SRE handbook","text":"<ul> <li>Golden Signals are like the health indicators of a system.</li> <li>They help us understand if the system is working well or not.</li> <li>There are four main golden signals:<ul> <li>Latency: \ud83d\udd52 How long it takes for the system to respond.</li> <li>Traffic: \ud83d\udea6 How much data the system is handling.</li> <li>Errors: \u274c How many mistakes the system is making.</li> <li>Saturation: \ud83d\udd04 How full the system is.</li> </ul> </li> </ul>"},{"location":"3.arch/","title":"Architecture","text":""},{"location":"3.arch/#otel-arch","title":"OTEL Arch","text":""},{"location":"3.arch/#simple-app-arch","title":"Simple App Arch","text":"<pre><code>graph LR\n    Fe((FrontEnd)) --&gt; A[App Backend] ---&gt; DB[Database]\n    A ---&gt; 3p[3P Svc]\n    A --&gt; Redis[Cache]\n    A --OTEL data points ------&gt;  otel[OpenTelemetry Collector/Agent]\n</code></pre>"},{"location":"3.arch/#ebpf-core","title":"eBPF core","text":""},{"location":"3.arch/#cilium-in-google-k8s","title":"Cilium in Google K8S","text":""},{"location":"3.arch/#full-cilium-capabilities","title":"Full Cilium Capabilities","text":""},{"location":"4.otel-components/","title":"OpenTelemetry Components","text":""},{"location":"4.otel-components/#collector","title":"Collector","text":"<p>The OpenTelemetry Collector is a vendor-agnostic agent for            - <code>collecting, processing, and exporting</code> telemetry data.</p>"},{"location":"4.otel-components/#sdk","title":"SDK","text":"<p>The OpenTelemetry SDK is a set of libraries that provide a way to        - <code>instrument, generate, collect &amp; export</code> telemetry data.</p>"},{"location":"4.otel-components/#exporters","title":"Exporters","text":"<ul> <li>Exporters are components that send telemetry data to a specific backend.</li> </ul>"},{"location":"4.otel-components/#instrumentation-libraries","title":"Instrumentation Libraries","text":"<ul> <li>Instrumentation libraries are used to instrument applications to collect telemetry data.</li> </ul>"},{"location":"4.otel-components/#propagators","title":"Propagators","text":"<ul> <li>Propagators are used to encode and decode context data for cross-process communication.</li> </ul>"},{"location":"4.otel-components/#distributed-components","title":"Distributed Components","text":""},{"location":"4.otel-components/#metrics","title":"Metrics","text":"<pre><code>\u251c\u2500\u2500 Prometheus\n\u251c\u2500\u2500 VictoriaMetrics  &lt;-----\n\u251c\u2500\u2500 InfluxDB\n\u251c\u2500\u2500 OpenTSDB\n\u2514\u2500\u2500 Cloud Providers\n</code></pre>"},{"location":"4.otel-components/#trace","title":"Trace","text":"<pre><code>\u251c\u2500\u2500 Jaeger\n\u251c\u2500\u2500 Zipkin\n\u251c\u2500\u2500 Grafana.Tempo  # &lt;----\n\u2514\u2500\u2500 Cloud Providers\n</code></pre>"},{"location":"4.otel-components/#logs","title":"Logs","text":"<pre><code>\u251c\u2500\u2500 Splunk\n\u251c\u2500\u2500 Kafka\n\u251c\u2500\u2500 Logstash\n\u251c\u2500\u2500 Fluentd\n\u2514\u2500\u2500 Cloud Providers # &lt;----\n</code></pre>"},{"location":"5.demo/","title":"Demo","text":"Get \u2192 Set \u2193   \u2190 Go"},{"location":"5.tuning-otel-comp/","title":"Tuning OTEL components","text":"Default Replacement USP Metrics Prometheus VictoriaMetrics Low Resource Usage Traces Jaeger Tempo Data Storage options Logs Any Any - Profiler Cloud Beyla + Pyroscope No code option Collector Single pod Daemonset Funnel Scalability Default Replace with USP Runtime SDK Each App Single-binary/package Full control over code <p>Suggestion </p> <p>Wrap all the otel inits in a function and use it everywhere.</p>"},{"location":"z-commands/","title":"Z commands","text":""},{"location":"z-commands/#available-in-2-modes","title":"Available in 2 modes","text":"<ul> <li>Docker compose mode</li> <li>KinD   cluster mode</li> </ul>"},{"location":"z-commands/#1docker-compose-mode","title":"1.Docker compose mode","text":"<pre><code>$ make otel\n</code></pre>"},{"location":"z-commands/#2-kubernetes-mode","title":"2. Kubernetes mode","text":"<p>NOTE: While experimenting this</p> <p>Do not use orbStack, it may be stop working due to resource demand and high network activity.</p> <p>Instead use  Docker-desktop</p>"},{"location":"z-commands/#1kind","title":"1.KinD","text":"<pre><code>$ cat local-setup/local-cluster.yaml\n\nkind: Cluster\napiVersion: kind.x-k8s.io/v1alpha4\nnetworking:\n  disableDefaultCNI: false   # &lt;--- This is for custom CNI like cilium\n  podSubnet: 192.168.0.0/16\nnodes:\n- role: control-plane\n- role: worker\n- role: worker\n</code></pre>"},{"location":"z-commands/#2local-alias","title":"2.Local alias","text":"<pre><code>alias ktl=\"kubectl\"\nalias kctx=\"kubectx\"\n</code></pre>"},{"location":"z-commands/#3create-a-cluster","title":"3.Create a  cluster","text":"<pre><code>$ kind create cluster \\\n  --config local-setup/local-cluster.yaml \\\n  --name otel-demo-cluster\n\n#Confirm\n&gt; kctx\nkind-otel-demo-cluster &lt;---------\nwealthy\n</code></pre>"},{"location":"z-commands/#4deploy","title":"4.Deploy","text":"<pre><code>ktl create ns otel\nktl -n otel apply -f kind-deployments\n</code></pre>"},{"location":"z-commands/#5port-forward-for-local-access","title":"5.Port forward for local-access","text":"<pre><code>$ ktl get svc -n otel\n\n$ ktl -n otel port-forward svc/grafana 3000:grafana-ui &gt; /dev/null &amp;\n$ ktl -n otel port-forward svc/otelcol 4317:otel-col &gt; /dev/null &amp;\n\n# kill\n$ lsof -i:3000 -t | xargs kill -9\n$ lsof -i:4317 -t | xargs kill -9\n</code></pre>"},{"location":"z-commands/#6standalone-services","title":"6.Standalone services","text":"<pre><code># python-app\n$ cd py-project\n$ source venv-otel-demo/bin/activate\n\n$ make deps run\n# running server on http://localhost:8000/docs/\n$ deactivate\n\n\n# ------\n# Go binary\n$ cd go-project  # From project root\n$ make run\n# running server on http://localhost:8080\n\n# -----\n# Try the apis\n$ curl -s http://localhost:8000/ping/ | jq\n$ curl -s http://localhost:8000/propagate/ | jq\n\n$ curl -s http://localhost:8080/api/ping/ | jq\n</code></pre>"},{"location":"z-commands/#7auto-instrumentation","title":"7.Auto instrumentation","text":"<pre><code># Load generator\n$ ktl apply -f https://raw.githubusercontent.com/keyval-dev/simple-demo/main/kubernetes/deployment.yaml\n\n# Install auto-instrumentor\n$ brew install keyval-dev/homebrew-odigos-cli/odigos\n$ odigos install\n\n$ odigos ui\n\n# Then configure the destination as OTLP gRPC with endpoint: otelcol:4317\n# Close odigos\n</code></pre>"},{"location":"z-commands/#8check-traces","title":"8.Check traces","text":"<pre><code>OpenLens -&gt;  GrafanaPod -&gt; Auto open portForward\n</code></pre>"},{"location":"z-commands/#9cleanup","title":"9.Cleanup","text":"<pre><code>$ ktl delete ns otel\n\n$ kind delete cluster --name otel-demo-cluster\n</code></pre>"},{"location":"z-commands/#transform-docker-compose-deployments","title":"Transform <code>docker-compose -&gt; deployments</code>","text":"<p>Already in-place <pre><code>$ mkdir kind-deployments\n$ cd kind-deployments\n$ MONGO_ROOT=dummy \\\n  kompose --file ../local-setup/local-dockercompose.yaml \\\n  convert --profile all\n</code></pre></p>"}]}